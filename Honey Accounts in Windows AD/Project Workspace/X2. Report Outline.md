# Introduction
- The defender's dilemma
	- Always harder to defend than it is to attack a system due to the nature of system complexity and power imbalance
	- With time, anyone can get in and exploit the system​ 
	- Don't put all your eggs in one basket​
	- Perimeter, analytics, EDR, etc.​
	- Easy to hide.  Hard to detect.
- Defining cyber deception
	- Using knowledge asymmetry to exploit false realities kind of like how Kevin McAlister deceives the burglars in Home Alone
- Cyber Deception in Literature

References to use:
- [Examining the Efficacy of Decoy-based and Psychological Cyber Deception | USENIX](https://www.usenix.org/conference/usenixsecurity21/presentation/ferguson-walter)
	* The paper you've provided focuses on the use of defensive cyber deception and its effects on attackers, particularly through the implementation of decoy systems and the influence of cyberpsychology. Here are key points and data from the paper that you can use in your paper, particularly relating to cyber deception, knowledge asymmetry, and exploiting false realities:
	* **Effectiveness of Decoy Systems in Cyber Defense**: The paper presents a controlled experiment (the Tularosa Study) involving over 130 professional red teamers in a network penetration test. The study investigates the effectiveness of decoy systems as a cyber defense strategy. These decoys, interspersed among real network assets, can be made to appear more or less vulnerable, thus affecting attacker behavior.
	* **Impact of Explicit Mention of Deception**: The study found that the combination of the presence of decoys and informing participants that deception might be present was the most effective in impacting cyber attack behavior. This suggests that the awareness of potential deception can significantly alter attacker strategies.
	* **Measurement of Attacker Resource Expenditure**: One measure of the success of cyber deception is the amount of time and effort attackers spend engaging with decoys. Interactions with these deceptive hosts are considered wasted efforts, thus delaying the attacker's progress.
	* **Altered Perception and Psychological Effects**: The study observed pronounced psychological effects on attackers caused by the altered perception resulting from deception. For instance, participants in the "Present-Informed" condition (where deception was used and attackers were informed about it) reported fewer failures, possibly due to a self-serving bias.
	* **Influence on Attacker's Decision-Making and Cognitive State**: The use of deception, both cyber and psychological, has been shown to affect the cognitive and emotional state of attackers. This includes inducing confusion, altering perceptions of success and failure, and potentially triggering decision-making biases.
	* **Importance of Information Management in Deception**: The paper suggests that managing how much information about deceptive defenses is shared with attackers is crucial. Over-sharing details could make the decoys less effective.
	* **Future Directions for Cyber Deception**: The paper proposes further exploration into cognitive biases prevalent in cyber attackers and how these can be intensified to disrupt attacks. This involves leveraging artificial intelligence for adaptive decoy systems and enhancing models to account for realistic human behavior in cyber operations.
	* **Cyber Deception as a Part of a Comprehensive Security Strategy**: The study concludes that while cyber deception can force attackers to waste resources and provide early warnings for attacks, it should be part of a broader security strategy that includes traditional best practices and behavior-based security hygiene.
- [Game Theory Approaches for Evaluating the Deception-based Moving Target Defense | Proceedings of the 9th ACM Workshop on Moving Target Defense](https://dl.acm.org/doi/abs/10.1145/3560828.3563995)
	- Moving target defense (MTD) is a proactive defensive mechanism proposed to disrupt and disable potential attacks, thus reversing the defender’s disadvantages. Cyber deception is a complementary technique that is often used to enhance MTD by utilizing misinformation to deceive and mislead attackers. Deception elements, such as honeypot, honey bait, honey token, breadcrumb, and well-constructed deception scenes, can significantly increase the uncertainties for attackers. Deception-based MTD techniques can change the asymmetry situation between defenders and attackers through affecting the attacker’s perception of the system. However, there is still a lack of understanding about the role of cyber deception in MTD, and few research works have evaluated the effectiveness of cyber deception.
	- In recent years, increasing security problems in cyberspace present new requirements to the existing security defense mechanisms. The certainty, homogeneity, and static nature of computer systems provide plenty of time and space for attackers to analyze the target systems and implement intrusion. Furthermore, current cyber defenses are mostly reactive as the response comes after attacks have happened. These characteristics provide attackers with significant advantages over defenders. Therefore, innovative defense techniques are needed to break such asymmetric situation. Moving target defense (MTD) [20] and cyber deception [27] are two main proactive defensive techniques proposed to disrupt and disable potential attacks, thus reversing the defender’s disadvantages [31]. The fundamental idea of MTD is to dynamically and randomly alter the attributes of a system, increasing the uncertainty and complexity for attackers. In comparison, cyber deception utilizes plausible-looking and carefully crafted misinformation to deceive and mislead attackers. Researches show that MTD techniques can be enhanced by the addition of deception [10]. MTD and cyber deception are complementary techniques that can be deployed by defenders simultaneously with common objectives to defeat the attackers. Due to its diversified deceptive methods, as well as the characteristics of low construction cost and easy construction of deceptive attributes, cyberspace deception provides a new direction for expanding the attack surface shifting space, and has become an important technical direction for MTD research. Approaches combining MTD and deception can be used in various domains (e.g., deception network [30], web deception [12], [35], data deception[36]). However, there are few systematic approaches to evaluate the effectiveness of deception in MTD techniques. Current approaches include evaluating by metrics, mathematical models or simulation methods. They have three shortcomings: 1) it is not clear how to quantify the deception effect in the network; 2) many MTD evaluation methods are applicable to specific technologies and limited to specific application scenarios, so they lack broad applicability; 3) the MTD system has the characteristics of dynamics and interaction complexity that traditional evaluation methods cannot propose a formal specification to describe.
	- Cyber deception mainly misleads the attacker’s actions by providing seemingly real but false information. Deception defense increases the shifting space of system’s attack surface. Deception elements, such as honeypot, honey bait, honey token, breadcrumb, well-designed deception stories, and wellconstructed deception scenes, create huge information entropy that forces the attacker into a deceptive environment where it’s difficult to distinguish the real target from the deceptive scenarios. Table 1 shows the comparison between MTD and cyber deception.
	- Adding a decoy. This technique is mainly used to draw the attacker’s attention away from the critical resource of a system. Decoys require the system to invent a number of carefullyprepared decoys with the goal of making the attacker believe that they are real. Honeypot is a typical example to deceive the attacker.
- [CONCEAL: A Strategy Composition for Resilient Cyber Deception-Framework, Metrics and Deployment | IEEE Conference Publication | IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/8433196)
	- Cyber deception is a key proactive cyber resilience technique to reverse the current asymmetry that favors adversaries in cyber warfare by creating a significant confusion in discovering and targeting cyber assets. One of the key objectives for cyber deception is to hide the true identity of the cyber assets in order to effectively deflect adversaries away from critical targets, and detect their activities early in the killchain.
- [SODA: A System for Cyber Deception Orchestration and Automation | Proceedings of the 37th Annual Computer Security Applications Conference](https://dl.acm.org/doi/abs/10.1145/3485832.3485918)
	- Active Cyber Deception (ACD) has emerged as an effective proactive cyber defense technique that can mislead adversaries by presenting falsified data and allow opportunities for engaging with them to learn novel attack techniques.
- [The Defender's Dilemma: Charting a Course Toward Cybersecurity | RAND](https://www.rand.org/pubs/research_reports/RR1024.html)
	- The defender's dilemma sums up the risk surfaces that arise at these borders.  Being a defender means covering all entry points or prioritizing certain ones. The attackers only need one way in, but the defender must cover the surfaces which the attacker will inevitably try to exploit.
# Opinions on Deception Tech
- Controversy and mixed opinions with cyber deception solutions and technology
	- Some support them a lot with great confidence. 
	- Others have little support but not great confidence in their opinion or great logical reasons for not supporting cyber deception technology
- High vs Low False Positive Contradiction
	- A lot of the opposition to cyber deception technology revolves around the lack of maturity, supposed high costs of implementation, and high number of false positives
	- A lot of the support relates to low cost of implementation (cost effectiveness) and low number of false positives
	- This shows a contradiction in opinions which likely relates to cyber deception's lack of maturity in the industry and how it can be implemented in a myriad of ways
	- Often the low false positives are akin to setting a tripwire in an area where entities aren't expected and assumed to be malicious if tripped such as a metaphorical vault like an admin account
	- With high false positives, it may be an implementation where tripping of the trap wasn't expected and yet there are complex system interactions at play that cause the detections to trip
- [Tribe of Hackers Blue Team [Book]](https://www.oreilly.com/library/view/tribe-of-hackers/9781119643418/)
	- "Has your organization implemented any deception technologies, and if so what effect has that had on the blue team’s detection capabilities?​"
	- ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214133949691.png)
	- Support:​
		- Early warning system​
		- Learn adversary techniques​
		- Visibility​
		- High returns​
		- Low False Positive Rate​
	- Opposition:​
		- Only for mature orgs​
		- Time is better spent elsewhere​
		- Not a mature market​
		- High False Positive Rate
	- High False Positives
		- Traps that detect normal behavior​
		- Traps that overlap with common areas
	- Lower False Positives
		- Traps in places people shouldn't ever be​
		- Look for "hard-to-fake" behavior
# Purpose & Motivation
- Popularized by Pentesting Firms
	- Active Defense Harbinger Distribution
- Coworkers talking of usage
# Password Statistics & Password Sprays
- Statistics on Passwords
- Studies relating to memory and passwords - convenience
- Password sprays in research

- Statistics
	- Sources:
		- [Too many passwords? How understanding our memory can increase password memorability - ScienceDirect](https://www.sciencedirect.com/science/article/abs/pii/S1071581917301581)
			- Passwords are the most common [authentication mechanism](https://www.sciencedirect.com/topics/computer-science/authentication-mechanism "Learn more about authentication mechanism from ScienceDirect's AI-generated Topic Pages"), that are only increasing with time. Previous research suggests that users cannot remember multiple passwords. Therefore, users adopt insecure password practices, such as password reuse in response to their perceived memory limitations.
		- 
	- Stats:
		- 24% of Americans use passwords like “password,” “Qwerty,” and ”123456.”​
		- 67% of all Americans use the same password for different online accounts​
		- 53% of people rely on their memories to handle passwords​
		- Compromised credentials - 61% of breaches​
		- 59% of Americans use a person’s name or a family member's birthday as a password​
		- Just 15% of Americans use an online password manager
		- Passwords usually need to be convenient (e.g. master passwords)
## Credentials: Targeted Attacks vs Wide-Nozzle Attacks
- Wide nozzle vs targeted
- Wide-Nozzle Profitability
- The Ineffectiveness of Targeted Attacks \& Wordlist Generation: Comparing Threat Models
	- Example of modern targeted attack with GPT 3
	- Why targeted attacks and wordlist generation aren't cost effective for password sprays
		- input too fast for stealthy output

- [Pump Up Password Security! Evaluating and Enhancing Risk-Based Authentication on a Real-World Large-Scale Online Service | ACM Transactions on Privacy and Security](https://dl.acm.org/doi/full/10.1145/3546069)
	* **Popularity of Password Spraying Attacks**: These attacks are popular because they can be easily scaled with minimal effort and have the potential for financial gain. The practice of users reusing passwords across different sites makes these attacks particularly effective.
- [ACM-Research/targeted-password-guesses: We refined a GPT-3 model on Wattpad user account data to generate targeted password guesses automatically.](https://github.com/ACM-Research/targeted-password-guesses/tree/main) 
	- using GPT 3 to generate targeted wordlists
* [[2309.03384] Measuring Website Password Creation Policies At Scale](https://arxiv.org/abs/2309.03384)
	* ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214175156524.png)
	1. **Limited Investigation of Password Policies**: Historically, there's been a lack of broad understanding of password policies due to manual evaluations and focus on a small number of top websites. This paper addresses this gap by applying an automated technique to infer password creation policies across over 20,000 sites.
	2. **Common Weaknesses in Password Policies**: The study found that most sites have minimal requirements for passwords. Over half of the analyzed sites allow passwords as short as six characters, and a significant 12% have no minimum length requirement. This leniency makes these sites vulnerable to password spray attacks, as attackers can exploit common, weak passwords like "password1234".
	3. **Lack of Use of Password Blocklists**: Only about 12% of sites were observed to use password blocklists. This means the majority of sites do not proactively prevent users from choosing passwords known to be compromised, which is a significant vulnerability in the context of password spray attacks.
	4. **Permissive Password Parameters**: The research indicates that many sites allow dictionary words, sequences, repeating characters, personal identifiers, and all-digit passwords. About 88% of sites even allow known breached passwords. Such permissive parameters increase the risk of successful password spraying attacks.
	5. **Top Sites vs. General Sites**: Top-ranked sites generally support stronger policy parameters compared to lower-ranked sites. However, even top sites show permissiveness in certain aspects like accepting dictionary words and breached passwords.
	6. **Guideline Adoption**: The paper reveals a mixed picture of guideline adoption. While some sites adhere to modern standards like NIST’s 2017 guidelines, a significant number still follow outdated practices, potentially leaving them vulnerable to password spray attacks.
	7. **Automated Password Policy Inference Method**: The paper’s methodology of automatically inferring password policies at scale is an innovative approach that provides a more comprehensive understanding of the current landscape of password policies on the web.
	8. **Variability in Policy Enforcement**: There is a considerable diversity in password policies across different websites, with many sites having unique policies. This variability can pose challenges for users in managing different password requirements and potentially lead to weaker password choices, increasing the risk of password spray attacks.
	- These points highlight the prevalent vulnerabilities in current password policies on a large scale, underscoring the risk of password spray attacks. The findings suggest that many organizations may need to strengthen their password creation policies to better protect against these types of attacks.
## Password Spray Mitigations
- MFA and SSO
- EDR and AV to avoid weird scripts
- FGPP in Windows Environments
- Time Series Analysis of Authentication

- [Pump Up Password Security! Evaluating and Enhancing Risk-Based Authentication on a Real-World Large-Scale Online Service | ACM Transactions on Privacy and Security](https://dl.acm.org/doi/full/10.1145/3546069)
	* **Persistence of Passwords as Primary Authentication**: Despite ongoing efforts to replace them, passwords remain the main method of authentication for most online services. This continued reliance on passwords, along with the increase in data breaches, exacerbates the vulnerability to attacks like credential stuffing and password spraying.
	* **Popularity of Password Spraying Attacks**: These attacks are popular because they can be easily scaled with minimal effort and have the potential for financial gain. The practice of users reusing passwords across different sites makes these attacks particularly effective.
	* **Low Adoption Rates of 2FA**: Despite being a strong mitigation strategy, two-factor authentication (2FA) has surprisingly low adoption rates. Examples include only 2.5% on Twitter and around 4% on Facebook as of 2021. Even Google's attempt to force 2FA on 150 million users (less than 10% of their user base) by the end of 2021 faced unclear outcomes in terms of user acceptance.
	* **User Resistance to 2FA**: Users tend to resist enabling 2FA, especially for non-sensitive or non-financial online services. This resistance poses a significant challenge in enhancing account security on a broader scale.
- [[2309.03384] Measuring Website Password Creation Policies At Scale](https://arxiv.org/abs/2309.03384)
	* ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214175156524.png)
	*   The paper you're referring to provides a comprehensive analysis of password creation policies across a wide range of websites, which is highly relevant for understanding the threat model and implications of password spray attacks. Here are key points from the paper that can be used in your paper on password spray attacks:
	1. **Limited Investigation of Password Policies**: Historically, there's been a lack of broad understanding of password policies due to manual evaluations and focus on a small number of top websites. This paper addresses this gap by applying an automated technique to infer password creation policies across over 20,000 sites.
	2. **Common Weaknesses in Password Policies**: The study found that most sites have minimal requirements for passwords. Over half of the analyzed sites allow passwords as short as six characters, and a significant 12% have no minimum length requirement. This leniency makes these sites vulnerable to password spray attacks, as attackers can exploit common, weak passwords like "password1234".
	3. **Lack of Use of Password Blocklists**: Only about 12% of sites were observed to use password blocklists. This means the majority of sites do not proactively prevent users from choosing passwords known to be compromised, which is a significant vulnerability in the context of password spray attacks.
	4. **Permissive Password Parameters**: The research indicates that many sites allow dictionary words, sequences, repeating characters, personal identifiers, and all-digit passwords. About 88% of sites even allow known breached passwords. Such permissive parameters increase the risk of successful password spraying attacks.
	5. **Top Sites vs. General Sites**: Top-ranked sites generally support stronger policy parameters compared to lower-ranked sites. However, even top sites show permissiveness in certain aspects like accepting dictionary words and breached passwords.
	6. **Guideline Adoption**: The paper reveals a mixed picture of guideline adoption. While some sites adhere to modern standards like NIST’s 2017 guidelines, a significant number still follow outdated practices, potentially leaving them vulnerable to password spray attacks.
	7. **Automated Password Policy Inference Method**: The paper’s methodology of automatically inferring password policies at scale is an innovative approach that provides a more comprehensive understanding of the current landscape of password policies on the web.
	8. **Variability in Policy Enforcement**: There is a considerable diversity in password policies across different websites, with many sites having unique policies. This variability can pose challenges for users in managing different password requirements and potentially lead to weaker password choices, increasing the risk of password spray attacks.
	- These points highlight the prevalent vulnerabilities in current password policies on a large scale, underscoring the risk of password spray attacks. The findings suggest that many organizations may need to strengthen their password creation policies to better protect against these types of attacks.
# Traditional Password Spray Detection Methods
- Univariate time series analysis - looking for spikes

* [Brute Force: Password Spraying, Sub-technique T1110.003 - Enterprise | MITRE ATT&CK®](https://attack.mitre.org/techniques/T1110/003/)
	* ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214203225046.png)
	* Monitor for many failed authentication attempts across various accounts that may result from password spraying attempts.
	* Typically, management services over commonly used ports are used when password spraying. Commonly targeted services include the following:
	- Monitor authentication attempts across various accounts through services like SSH (22/TCP), Telnet, FTP, LDAP, Kerberos, RDP

# Modern Univariate Time Series Anomaly Detection
- Why time series analysis is cost effective, useful, or simple especially with authentication related data
- Univariate time series analysis types
	- statistical types, how univariate time series analysis and anomaly detection has changed over time, and where it's going
- The issue of univariate time series such as with authentication time series data across an organization
	- This data has natural or seasonal spikes throughout a period like a month or day, and the time series may even trend upwards or downwards. This happens with, for example, with authentication data during a holiday (trend) and with people going to sleep (seasonality).  
	- Simple moving average spike detection is not as accurate and therefore methods that account for these aspects are better and modern for detections
- STL decomposition
	- Explain STL decomposition 
	- Explain the value of STL decomposition with detecting password sprays based on the leftover residual which accounts for login failure patterns
- SARIMAX, SARIMA, ARIMA models
	- Explain how SARIMAX, SARIMA, and ARIMA models can be used to detect password sprays
	- Explain why this is a great stepping stone to get out of simpler statistical detections
- Conclude by talking about a multivariate approach and how it is likely more effective but less accessible to security operations engineers who may be unfamiliar or not have to time to design and implement ML and AI models

* [[2004.00433] Anomaly Detection in Univariate Time-series: A Survey on the State-of-the-Art](https://arxiv.org/abs/2004.00433)
	* ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214175851398.png)
	*   The paper provides a comprehensive overview of various anomaly detection methods applied to time-series data, especially in the context of detecting anomalies like password spray attacks. Here's a summary reflecting on modern time series analysis methods and their applications:
	* **Evolution of Time-Series Anomaly Detection**: The paper highlights the transition from traditional statistical approaches to machine learning and deep learning techniques in anomaly detection for time-series data. This evolution mirrors the growing computational power and the increasing complexity of datasets.
	* **Cost-Effectiveness and Utility of Time-Series Analysis in Authentication Data**: Time-series analysis is particularly useful for detecting anomalies in authentication data because it can identify unusual patterns over time, which are indicative of attacks like password spraying. This method is cost-effective as it leverages existing data logs and can be automated, reducing the need for manual analysis.
	* **Challenges with Univariate Time-Series Analysis**: Univariate time-series analysis, which examines a single data sequence, can be problematic in the context of authentication data. This is because such data often exhibits natural or seasonal variations (e.g., login frequency changes during holidays or nighttime). Traditional methods like simple moving average spike detection may not accurately account for these variations, leading to false positives or negatives.
	* **STL Decomposition for Anomaly Detection**: Seasonal and Trend decomposition using Loess (STL) is a robust method for decomposing a time series into seasonal, trend, and residual components. This decomposition is valuable in identifying password sprays by focusing on the residual component, which can highlight anomalies once the regular patterns (seasonality and trend) are accounted for.
	* **Use of SARIMAX, SARIMA, and ARIMA Models**: These models are advanced statistical methods for analyzing and forecasting time-series data. SARIMA (Seasonal Autoregressive Integrated Moving Average), ARIMA (Autoregressive Integrated Moving Average), and SARIMAX (Seasonal Autoregressive Integrated Moving-Average with Explanatory Variable) models are particularly useful for password spray detection as they can model both seasonal variations and trends in authentication data. These models represent a significant improvement over simpler statistical methods, offering a more nuanced understanding of time-dependent patterns.
	* **Future of Anomaly Detection in Time-Series Data**: The paper suggests that the future of anomaly detection in time-series data lies in the refinement and application of machine learning and deep learning methods. These approaches can handle larger datasets and are more adaptable to the complex and evolving nature of cybersecurity threats like password spraying.
* [A Review on Outlier/Anomaly Detection in Time Series Data | ACM Computing Surveys](https://dl.acm.org/doi/abs/10.1145/3444690)
	* ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214175731897.png)
	* **Cost-Effectiveness and Utility of Time Series Analysis in Authentication Data**: Time series analysis is particularly cost-effective for analyzing authentication data because it leverages automated techniques to process large volumes of data over time. This is far more efficient than manual review, and it can reveal insights about user behavior and potential security threats that might be missed otherwise.
	* **Univariate Time Series Analysis Types**:
	    - Statistical types of univariate time series analysis methods have evolved from basic statistical models to incorporate more sophisticated techniques that can handle the dynamic nature of time-dependent data.
	    - Anomaly detection in time series has shifted from simple threshold-based detections to advanced statistical models that can predict and estimate expected behavior, allowing for the identification of anomalies based on deviations from these expectations.
	    - The paper discusses moving beyond basic models like AR (Autoregressive) and MA (Moving Average) to combinations like ARMA (Autoregressive Moving Average) and ARIMA (Autoregressive Integrated Moving Average), which can better account for complex patterns in data.
	- **Issues with Univariate Time Series**:
		- Authentication data naturally includes patterns and trends, such as seasonal spikes or behavioral changes over time. These can obscure the detection of anomalies if not properly accounted for.
		- Simple moving averages and basic threshold-based methods are not accurate in the face of such data because they do not account for underlying patterns like trends and seasonality.
	- **STL Decomposition**:
	    - STL decomposition is a robust method for decomposing time series into seasonal, trend, and residual components.
	    - For detecting password sprays, STL decomposition can be particularly valuable because the residual component can isolate anomalies from regular login patterns, which might indicate malicious activity.
	- **SARIMAX, SARIMA, and ARIMA Models**:
	    - These models are capable of detecting patterns and predicting future values in time series data by accounting for seasonality (SARIMA), trends (ARIMA), and external factors (SARIMAX).
	    - The ability of these models to adapt to time series with trends and seasonality makes them more advanced and accurate for detecting password sprays, which may manifest as deviations from predicted login patterns.
	- **Advancement to Machine Learning Techniques**:
	    - The paper suggests that there is a trend towards using more complex machine learning and deep learning methods for anomaly detection in time series data.
	    - Techniques such as LSTM (Long Short-Term Memory) networks and autoencoders, which are forms of neural networks, can learn to predict normal behavior and, thus, can detect anomalies based on deviations from learned patterns.
* [ARIMA Supplemented Security Metrics for Quality Assurance and Situational Awareness | Digital Threats: Research and Practice](https://dl.acm.org/doi/abs/10.1145/3376926)
	* **Univariate Time Series Analysis Types**:
		* The field has evolved from simple statistical methods to sophisticated ARIMA (AutoRegressive Integrated Moving Average) models that can capture complex patterns in data.
		- Univariate time series analysis has expanded to include machine learning techniques that can improve anomaly detection over time, adapting to new patterns of data as they emerge.
	- **Issues with Univariate Time Series in Authentication Data**:
		- Authentication data often exhibit seasonal trends and patterns. For instance, login attempts may peak during certain hours of the day or drop during holidays.
		- ARIMA models can handle these patterns by differencing the data to achieve stationarity, which means making the data stable over time without long-term trends or seasonal effects.
	- **STL Decomposition**:
		- STL (Seasonal and Trend decomposition using Loess) decomposition is valuable for separating the seasonal component and the trend from the "noise" where anomalies such as password sprays might be hidden.
		- By analyzing the residuals (the noise), which are the components left after removing seasonality and trend, STL decomposition can help in pinpointing outliers that might indicate password spray attempts.
	- **SARIMAX, SARIMA, and ARIMA Models**:
		- These models are suitable for detecting password sprays because they can forecast future values based on past data, considering trends, seasonality (SARIMA), and even external variables (SARIMAX).
		- Transitioning to these models from simpler statistical ones represents progress in time series analysis by providing a more nuanced understanding of data and its anomalies.
	- The paper discusses how ARIMA models, which are typically used to model stationary time series, can be applied to security metrics to enhance situational awareness and quality assurance for CSIRT (Computer Security Incident Response Team) services. By incorporating ARIMA models, security practitioners can forecast future events and identify deviations that may signal anomalies such as password sprays.
	- The paper emphasizes the application of ARIMA-supplemented metrics to facilitate and support services for CSIRTs by integrating them into existing best practices. This method is exemplified by integrating ARIMA metrics into processes for quality assurance and situational awareness, demonstrating how they can be used to support data analysts and security practitioners.
	- Furthermore, the paper validates the application of ARIMA models to threat intelligence data and situational awareness by applying them to data feeds from the SANS Internet Storm Center (ISC) and DShield. This approach is shown to detect anomalies effectively and provide a baseline for normal behavior, which is critical in identifying password sprays and other malicious activities.
	- In conclusion, the paper asserts the potential of ARIMA-supplemented metrics in improving the precision and meaningfulness of security metrics and thereby aiding in decision-making processes for CSIRT services. Future work could explore more complex approaches to anomaly detection, automate the correlation of outliers with other threat intelligence sources, and investigate the applicability of these methods across various CSIRT services and platforms.
	- Quality assurance and situational awareness are important areas of interest for CSIRTs and security teams. Significant efforts have been made on defining metrics measuring critical parameters for these fields of application. However, methodical approaches are missing or lacking precision to enable a reliable usage of such metrics for quality assurance and situational awareness. In this contribution, we introduce a method that generalizes the application of ARIMA time series analysis on a well-defined set of metrics (ARIMA supplemented metrics) to facilitate and support quality assurance and situational awareness services. This method is based on research on ARIMA models and metrics and builds on CSIRT best practices. We show how data analysts and security practitioners can incorporate this method into existing best practices for CSIRT services pertaining to quality assurance and situational awareness. The applicability of this method is demonstrated by integrating ARIMA supplemented metrics into exemplary processes for quality assurance and situational awareness to support data analysts and security practitioners in CSIRTs and security teams.
	- Quality assurance in the context of time series analysis for authentication data is significant because it ensures the reliability and accuracy of the data being analyzed.
	- In cybersecurity, particularly in detecting password sprays, high-quality data is crucial for the models to correctly identify genuine anomalies as opposed to false positives or negatives.
	- The paper highlights that quality assurance helps maintain the integrity of threat intelligence data. By applying ARIMA models, security teams can measure and validate the quality of data feeds, which is crucial for maintaining high standards in threat detection.
	- Robust quality assurance protocols, as discussed in the paper, can lead to improved performance and accountability within CSIRT services. ARIMA-supplemented metrics provide a mathematical basis for validating quality parameters, leading to more informed decision-making and more effective incident response strategies.
	- The integration of ARIMA models for quality assurance allows CSIRTs to forecast with confidence, understand the underlying patterns in security incidents, and provide a systematic approach to maintaining data quality over time.
	- Ultimately, ensuring data quality means that CSIRTs can rely on their analytical systems to flag potential security breaches proactively, thereby strengthening their overall security posture and reducing the risk of successful cyber attacks.
* [The Role of Machine Learning in Cybersecurity | Digital Threats: Research and Practice](https://dl.acm.org/doi/full/10.1145/3545574)
	* ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214175905236.png)
	* ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214175909206.png)
	* ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214175914225.png)
		*  Specifically, SARIMA analyzes a time series by adopting a sliding window approach: All data points within a given time window are considered by SARIMA to predict a “future” value, which is provided alongside a confidence range. We provide an example of SARIMA in Figure 14, showing the time series of the transmitted packets aggregated in time slots of 5 minutes, over a period of 1 week; the sliding window considered by SARIMA is of 30 minutes. The actual values are reported in dark blue, whereas the values predicted via SARIMA are shown in orange; the confidence window of each predicted value is shown in light blue: therefore, actual values that fall outside of this range are treated as anomalous. In particular, vertical gray lines denote the anomalies detected by SARIMA. From Figure 14, we observe that SARIMA accurately detects stationary deviations. However, SARIMA can only detect non-stationary changes when they happen within its sliding window. Furthermore, non-stationary (but legitimate) changes that occur after a long stationary interval are falsely detected as anomalies by SARIMA. Despite some incorrect predictions, the considered application of SARIMA obtained a performance that was deemed appropriate for the given task and integrated in CAIAC.
		* **Real-world Applicability**: The paper describes a real-world application of the SARIMA model using data from the SANS ISC's DShield feed. This application underscores the model's practicality in processing and analyzing real-world data for cybersecurity purposes.
		* **Operational Trade-offs**: The paper also discusses the operational trade-offs when deploying machine learning models like SARIMA in cybersecurity. While SARIMA can provide accurate predictions, it may require substantial computational resources, and there is a balance to be struck between accuracy, timeliness, and computational overhead.
		* **Non-Intrusive Operation**: SARIMA models can be implemented in a non-intrusive manner, which is vital for industrial control systems (ICS) and other sensitive environments where cybersecurity tools must not interfere with operational processes.
		* **Adaptability**: The adaptability of SARIMA models to different types of time series data makes them versatile tools in the cybersecurity toolkit. Whether it's network traffic, login attempts, or other types of security-related time series data, SARIMA models can be tuned to the specific characteristics of the dataset.
		* **Data Requirements**: The paper notes that the effectiveness of SARIMA models depends on the availability of comprehensive and clean historical data. The accuracy of predictions is tied to the quality of the input data, which must be representative of the underlying processes and free from significant gaps or anomalies.
* [Time series big data: a survey on data stream frameworks, analysis and algorithms | Journal of Big Data | Full Text](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-023-00760-1)
	* ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214180055140.png)
	* ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214180059848.png)
	* The SARIMA model, which stands for Seasonal Autoregressive Integrated Moving Average, is a sophisticated version of the ARIMA model that adds seasonality components. This model is particularly suitable for cybersecurity teams dealing with time-series data, such as authentication logs, because it can handle both non-seasonal and seasonal trends and patterns.
	* Password spray attacks often show a cyclical pattern, corresponding with times when attackers expect lower vigilance, such as during non-working hours or holidays. SARIMA can help in detecting such patterns by considering the seasonal fluctuations in the authentication attempts, which may not be captured by simpler models.
	* Time series anomaly detection can be taxonomized into several types:
		* **Statistical Approaches**: These include parametric methods (e.g., models based on the normal distribution) and non-parametric methods (e.g., kernel density estimation). They are typically used for point anomalies.
		* **Machine Learning & Deep Learning Approaches**: These can be unsupervised (like clustering or Principal Component Analysis) or supervised (like classification with Support Vector Machines). They can handle more complex anomalies, including contextual and collective anomalies.
		* **Distance-Based**: Such methods identify anomalies by looking at the distance or similarity between points in a dataset.
		* **Density-Based**: These focus on the density of the surrounding neighborhood of a data point.
		* **High-dimensional Approaches**: These are used when data have a large number of features, and might include techniques like autoencoders.
		* **Temporal Approaches**: Long Short-Term Memory (LSTM) networks and Recurrent Neural Networks (RNNs) fall into this category. These are especially relevant for detecting time-related anomalies in series like repeated failed login attempts over time.
		* Detecting password sprays using SARIMA or similar time series models fits into the temporal approaches category. SARIMA can be an effective "gateway" model that introduces security teams to the benefits of more complex ML and AI techniques without the steep learning curve associated with deep learning models. It is an intermediate step that balances sophistication with interpretability and computational efficiency.
* [Advancing Password Spray Attack Detection - Microsoft Community Hub](https://techcommunity.microsoft.com/t5/microsoft-entra-blog/advancing-password-spray-attack-detection/ba-p/1276936)
	* **Password Spray Attack Description**: Password spray attacks involve trying a few common passwords against many accounts across different organizations. This attack strategy aims to bypass traditional security measures like account lockout and IP address blocking. From an individual tenant's perspective, these attacks are hard to detect due to their low frequency and inconsistency.
	* **Traditional Detection Limitations**: Conventional methods to detect password spray attacks, such as monitoring failed login attempts from specific IP addresses, are often ineffective due to the distributed and low-frequency nature of these attacks.
	* **Use of Global Signal and Machine Learning**: The approach described in the paper utilizes global signal - data collected across numerous tenants worldwide - combined with machine learning technology. This global perspective is crucial for identifying patterns that are not observable within the data of a single tenant.
	* **Pattern Recognition in Time Series Data**: The detection method employs time series analysis of login attempts. Each color in the provided chart represents a different password hash for login attempts. In normal conditions, this data would appear flat and evenly dispersed. However, a password spray attack manifests as a significant spike in a single password hash failing across many accounts, which is detectable in the aggregated global data.
	* **Transition from Heuristic to Machine Learning Detection**: Initially, a heuristic approach was used for detection, which was effective but limited. The evolution to a machine learning system allowed for the incorporation of additional data points like IP reputation and unfamiliar sign-in properties. This method represents a shift from univariate analysis (looking at a single variable, e.g., failed login attempts) to a more complex, likely multivariate approach where multiple variables (IP reputation, login patterns, etc.) are considered.
	* **Improved Detection Performance**: The new ML-based detection system shows a 100% increase in recall over the heuristic algorithm, meaning it detects twice the number of compromised accounts. It also maintains a high precision rate, indicating a low rate of false positives.
* [Offensive Technique Details | MITRE D3FEND™](https://d3fend.mitre.org/offensive-technique/attack/T1110.003/)
	* ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214203546057.png)
	* ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214202821990.png)
	* Authentication Event Thresholding
		* Collecting authentication events, creating a baseline user profile, and determining whether authentication events are consistent with the baseline profile.

# Dilemmas in Other Credential Attack Detection Methods
- UEBA - User and Entity Behavior Analytics
	- ML & AI processing user behavior
	- "you're not supposed to be here"
	- Requires divulging of some level of identity information or connection to identity.
- Indirectly reveal passwords via some cryptographic-related scheme and do analytics that way
	- password sprays could be obvious if the actual password like "Password1" or the hash could be viewed.  The detection for password sprays would then look something like "if same password is used across multiple accounts then password spray." This could also detect it if the attacker is rotating their IP address. The problem with this is that the detection method subverts security objectives in its implementation. 

- ["My Privacy for their Security": Employees' Privacy Perspectives and Expectations when using Enterprise Security Software | USENIX](https://www.usenix.org/conference/usenixsecurity23/presentation/stegman)
	* **Employee Awareness and Misconceptions**: A major finding of the paper is the lack of clear communication and understanding among employees about what data ESS collects. Many participants underestimated the extent of data collection, leading to privacy concerns and trust erosion between employees and employers.
	* **Data Collection for Security**: While the paper doesn't delve into UEBA specifically, it mentions the use of behavior analytics in ESS. This is relevant because UEBA also relies on analyzing user behavior data to identify anomalies and potential security threats, similar to what EDR solutions do.
	* **Potential Relevance to UEBA**: While the paper doesn't discuss UEBA in detail, its findings are indirectly relevant. The concerns about privacy, lack of awareness, and the need for effective communication and controls in ESS can be extrapolated to UEBA systems. These systems also collect and analyze detailed user behavior data, which could raise similar concerns among employees.
	* The paper highlights the challenge of balancing security needs with privacy concerns. In the context of credential attacks, while having access to password hashes could enhance the detection capabilities of security systems (by allowing them to identify unusual access patterns or repeated use of common passwords), it also increases the risk to user privacy. If this sensitive data were to be leaked or compromised, it could lead to significant security breaches.
- [Gossamer: Securely Measuring Password-based Logins | USENIX](https://www.usenix.org/conference/usenixsecurity22/presentation/sanusi-bohuk)
	* Pspray
		* "a new login service instrumentation tool called Gossamer. It securely records information about login requests, including certain carefully chosen statistics about the passwords used in the requests"
*  [Araña: Discovering and Characterizing Password Guessing Attacks in Practice | USENIX](https://www.usenix.org/conference/usenixsecurity23/presentation/islam)
	* Hard to find ground truth labels for logins
		* "Understanding and characterizing attacker strategies is critical to improving security, but doing so has been challenging thus far due to the sensitivity of login services and the lack of ground truth labels for benign and malicious login requests."
	* Psprays
		-   The information provided offers valuable insights into the challenges and methodologies related to detecting and defending against password spray attacks, particularly in the context of credential stuffing. Here's a summary focused on the applicability to password sprays, the dilemmas of detection without concrete evidence, and relevant data for a paper on password sprays:
			1. **Deployment and Data Collection Challenges**: Gossamer, a tool deployed at two universities (U1 for seven months and U2 for three months), highlights the difficulty in identifying attacks. The lack of "ground truth" in the dataset makes it challenging to use supervised machine learning for attack detection, as there is no definitive proof of what constitutes an attack within the data
			2. **Araña Analysis Pipeline**: To overcome these challenges, a new analysis pipeline called Araña was developed. Unlike traditional methods, Araña focuses on sets of login requests from the same IP within a day. This approach allows for the emergence of patterns indicative of client behavior. It employs unsupervised learning (agglomerative clustering with a custom distance function) to identify clusters of login sets, which can then be manually analyzed to uncover attack campaigns.
			3. **Credential Stuffing Attacks Discovery**: Araña was effective in identifying 29 attack clusters, many of which were high-volume credential stuffing attacks. These attacks often used breached username-password pairs and varied in their approach, from rapid, high-volume attacks from a few IPs to distributed, low-rate attacks from multiple IPs. This variety in attack strategies demonstrates the attackers' efforts to evade detection, particularly those measures focusing on individual high-volume IPs.
			4. **Detection of Targeted Attacks**: Araña also proved useful in uncovering lower-volume, targeted attacks. For instance, one identified campaign targeted 127 users with an average of 25 guessed passwords per user, including some successful logins. This indicates that targeted strategies can be effective for attackers.
			5. **Implications for Authentication System Designers**: The study's findings emphasize that credential stuffing remains a major threat vector for account compromise. Many compromised users had passwords previously exposed in breaches, underlining the need for breach alerting APIs and other proactive security measures.
			6. **Broader Context of Online Guessing Attacks**: Credential stuffing is part of a broader category of online guessing attacks, which also includes password spraying (using popular passwords against many accounts) and credential tweaking (using variations of breached passwords). The research also mentions the development of natural language processing techniques to improve guess generation, further complicating the defense against these attacks
		- In summary, this research provides significant insights into the nature and detection of password spray and related attacks, highlighting the complexities of detection without clear evidence and the need for innovative approaches like Araña. This information is highly relevant for a paper on the relevance and defenses against password spray attacks.
# Honey User Accounts for Password Spray Detection
- What are honey user accounts
- The threat model
	- Relate to attackers that are already on a Windows AD network and trying to escalate privs or laterally move in the environment
	- Talk about the type of attacker that would do it 
		- with "script kiddies" (explain what those are) they will be fast and "loud"
		- with APTs (explain them and give examples from Mitre) they will be low and slow and sporadic to blend in
- Honey User Hypothesis
	- Way cheaper than other detections.  It's a simple detection of whether the specific account has been interacted with or attempted authentication
	- Easy to setup
	- The account can be configured to allow for successful logins, but not allow the user in. In other words, they can successfully authenticate, but then access isn't granted to the host machine.  Explain why this is important since attackers cannot actually use the account or how it can be implemented with fake networks and services which would require more management to keep working and looking fake.

* [Offensive Technique Details | MITRE D3FEND™](https://d3fend.mitre.org/offensive-technique/attack/T1110.003/)
	* ![](../../__attachments/Honey%20Accounts%20in%20Windows%20AD/Project%20Workspace/IMG-20231214203546057.png)
	* A Credential created for the purpose of deceiving an adversary. A detection analytic is developed to determine when a user uses decoy credentials. Subsequent actions by that user may be monitored or controlled by the defender.
	* Decoy credentials should be integrated with a larger decoy environment to ensure that when decoy credentials are compromised, the credentials are used to interact with a decoy asset that is being monitored.
	* Continuous maintenance and updates are needed to ensure the legitimacy of the larger decoy environment and specifically the assets that utilize the decoy credentials.
# Implementation

## Threat Model & Architecture Setup
- Windows Active Directory Environment for IAM
- Threat Model: Lateral Movement and Priv Esc Threat Model: Assume attacker has access to an account on the network and is going to do internal recon to find DCs and admin accounts to try password spraying along with rest of users too
- Deployed infrastructure in Azure using an ARM template (azure resource manager) which costed about 10 dollars daily
	- Sets up logging infrastructure and various separate logical networks for attackers and defenders and domain controller
- AD Domain Creation and Pollution for testing in realistic environment – Badblood​
	- Gives me an environment to initially work with​ that is completely random and polluted with hundreds of users and relationships
	- Great for testing attack and detection​ - purple teaming
	- Process:​
		- Build Org Units​
		- Create User Accounts​
		- Nested and Randomized Group Structure​
- Honey Account Creation in AD – Remote Admin Tools in Powershell
- Attack​
	- Bloodhound -Detecting relationships in AD (with graph theory and Neo4J)​.  Beautiful interface which used Cypher queries to process relationships in AD and find accounts with high value of weaknesses
	- Plumhound – simplifying the Bloodhound data (made for blue/purple teams)​
	- Bruteloops – credential attacks and password spray​
	- BFG – framework that uses Bruteloops for password sprays
- Purple Teaming – attack & detection ​
- Detection setup - Azure Sentinel with Azure Monitor logs – KQL (kusto) for the query language
## Fake User Account Generation
- Fake user generation was simple
- Install PS dependencies on Windows 10 system
- Then we Add new user Objects that we control
- We then deploy Deception
- Using Deception we create a decoy user and computer
- We then make the new accounts look interesting to an attacker
- These accounts had no actual power. They let the user authenticate, but then deny the user when actually trying to access the system, so it was sort of like a banner and it would still log any attempts to authenticate in detail

## Password Spray Method
- Used a simple VERY LOUD tool called DomainPasswordSpray.ps1 to spray the whole domain with simple passwords
- Also used Bruteloops (more APT style low and slow implementation - hard to do though when project attack can only last a day for costs):
	- A dead simple library providing the foundational logic for efficient password brute force attacks against authentication interfaces.
	- Some features of Bruteloops that are relevant
		- protocol agnostic - If a callback can be written in Python, BruteLoops can be used to attack it
		- **Guess scheduling** - Each username in the SQLite database is configured with a timestamp that is updated after each authentication event. This means we can significantly reduce likelihood of locking accounts by scheduling each authentication event with precision.
		- -**Attack resumption** - Stopping and resuming an attack is possible without worrying about losing your place in the attack or locking accounts.
		- **Multiprocessing** - Speed up attacks using multiprocessing! By configuring the parallel guess count, you're effectively telling BruteLoops how many usernames to guess in parallel.
		- **Logging** - Each authentication event can optionally logged to disk. This information can be useful during red teams by providing customers with a detailed attack timeline that can be mapped back to logged events.
- To password spray, with DomainPasswordSpray it was as simple as running the command with a password
- For Bruteloops, I had to use impacket with some linux CLI transformations of the data to ingest into Bruteloops as a list of accounts to spray

# Results & Password Spray Detection Method Comparison
For password spray detection I implemented Kusto Query Language queries using both the decoy user account method and the STL decomposition method which was inspired by univariate time series anomaly detection research. Decoy user account failure was incredibly simple to detect and easy to expand on by using other event IDs with the decoy accounts. For STL decomposition I used the native function from Azure kql "series_decompose_anomalies". 

## Fake User Account Alerts
- I created two deceptive user accounts Heloisse Brinn and Luis Graves. The results of them getting password sprayed were incredibly simple. I could look for any account login attempt IDs and get simple results including who tried accessing them.

## Time Series Anomaly Detection
- STL was also quite effective at analyzing the password spray, but this was likely due to the fact that the password spray was not low and slow, but rather password sprayed hundreds of accounts at once became enough of an anomaly at that point. 
## Comparing Methods
- The STL method is interesting to look at and can reveal other characteristics of activity in a domain. However, it merely shows that a password spray is taking place. Any additional investigation requires further querying. Whereas the decoy user account method is far superior for many reasons. For one, you can automatically have data in the query results showing accounts that did the attempt. This could be used with security automation to automatically respond and without wasting any more compute in the SIEM. Also, this method can be used on any analytics platforms. Some platforms may take weeks to set up or figure out how to implement STL decomposition and the SARIMA model on. Therefore, the decoy user account method is way better.
# Conclusion
- .
# Unused Research
* [Encouraging users to improve password security and memorability | International Journal of Information Security](https://link.springer.com/article/10.1007/s10207-019-00429-y#citeas)
* [An Evaluation of Anomaly Detection and Diagnosis in Multivariate Time Series | IEEE Journals & Magazine | IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/9525836)
* [Jump-Starting Multivariate Time Series Anomaly Detection for Online Service Systems | USENIX](https://www.usenix.org/conference/atc21/presentation/ma)
* [USAD | Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining](https://dl.acm.org/doi/abs/10.1145/3394486.3403392)
* [Towards Building Intrusion Detection Systems for Multivariate Time-Series Data | SpringerLink](https://link.springer.com/chapter/10.1007/978-3-030-96057-5_4?error=cookies_not_supported&code=6f0afd3d-a20f-42e3-b571-ff253fc861d8#citeas)
* [A Survey on Device Behavior Fingerprinting: Data Sources, Techniques, Application Scenarios, and Datasets | IEEE Journals & Magazine | IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/9375484)
	* [2008.03343.pdf](https://arxiv.org/pdf/2008.03343.pdf)
* [Deep Learning for Anomaly Detection in Time-Series Data: Review, Analysis, and Guidelines | IEEE Journals & Magazine | IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/9523565)
* [[2308.00393] A Survey of Time Series Anomaly Detection Methods in the AIOps Domain](https://arxiv.org/abs/2308.00393)
- [Time-Series Anomaly Detection Service at Microsoft | Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining](https://dl.acm.org/doi/abs/10.1145/3292500.3330680)